{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf221c3",
   "metadata": {},
   "source": [
    "### 第十八章 概率潜在语义分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20bb80bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.69429943e-001],\n",
       "        [0.00000000e+000, 8.54447077e-002, 1.88922108e-001,\n",
       "         0.00000000e+000],\n",
       "        [4.00000000e-001, 0.00000000e+000, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 3.03504563e-001, 8.33062553e-114,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 2.62949463e-001,\n",
       "         8.15815746e-029],\n",
       "        [4.00000000e-001, 2.73359907e-001, 1.83322435e-001,\n",
       "         3.22280229e-001],\n",
       "        [0.00000000e+000, 0.00000000e+000, 2.17942553e-037,\n",
       "         1.69429943e-001],\n",
       "        [0.00000000e+000, 3.03504563e-001, 6.78126378e-114,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 3.41862603e-002, 3.64805994e-001,\n",
       "         0.00000000e+000],\n",
       "        [2.00000000e-001, 0.00000000e+000, 3.59899419e-040,\n",
       "         1.69429943e-001],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.69429943e-001]]),\n",
       " array([[5.78038404e-10, 1.00000000e+00, 1.44936677e-19, 2.65371283e-38,\n",
       "         5.50609943e-21, 7.53779798e-37, 7.00874816e-28, 1.00000000e+00,\n",
       "         2.81377469e-47],\n",
       "        [2.89232218e-62, 3.41907274e-53, 2.95652664e-69, 1.00009317e-60,\n",
       "         1.15791952e-43, 5.50875575e-31, 1.00000000e+00, 1.75665794e-67,\n",
       "         7.17937353e-01],\n",
       "        [2.98927764e-01, 4.59843542e-62, 4.95743319e-79, 3.60594287e-71,\n",
       "         1.16119867e-53, 1.00000000e+00, 8.89042703e-62, 4.66193787e-77,\n",
       "         2.82062646e-01],\n",
       "        [7.01072235e-01, 1.23415201e-40, 1.00000000e+00, 1.00000000e+00,\n",
       "         1.00000000e+00, 1.96968131e-47, 6.08392180e-38, 1.41953406e-28,\n",
       "         1.18020296e-58]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "def PLSA(X:np.ndarray, k:int, max_iter: int=100) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    概率潜在语义分析的EM算法\n",
    "    :param X 样本数据矩阵\n",
    "    :param k 话题数量\n",
    "    :return P(w_i|z_k)\n",
    "    :return P(z_k|d_j)\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "\n",
    "    # p_w_z = np.ones((m, k)) / m\n",
    "    # p_z_d = np.ones((k, n)) / k\n",
    "    p_w_z = np.random.rand(m, k)\n",
    "    p_w_z = p_w_z / p_w_z.sum(axis=0, keepdims=True)  # 按列归一化（每个话题下所有词的概率和为1）\n",
    "    p_z_d = np.random.rand(k, n)\n",
    "    p_z_d = p_z_d / p_z_d.sum(axis=0, keepdims=True)  # 按列归一化（每个文档下所有话题的概率和为1）\n",
    "\n",
    "\n",
    "    num_iter = 0\n",
    "    while num_iter < max_iter:\n",
    "        num_iter += 1\n",
    "\n",
    "        # E步骤\n",
    "        joint_prob = p_w_z[:, :, np.newaxis] * p_z_d[np.newaxis, :, :]  # shape: (m, k, n)\n",
    "        denominator = joint_prob.sum(axis=1, keepdims=True)  # shape: (m, 1, n)\n",
    "        p_z_wd = joint_prob / (denominator + 1e-10)  # 加小值避免除零，shape: (m, k, n)\n",
    "\n",
    "        # M步骤\n",
    "        numerator_wz = (X[:, np.newaxis, :] * p_z_wd).sum(axis=2)  # shape: (m, k)\n",
    "        denominator_wz = numerator_wz.sum(axis=0, keepdims=True)  # shape: (1, k)\n",
    "        new_p_w_z = (numerator_wz / (denominator_wz + 1e-10)).copy()  # 按列归一化\n",
    "        \n",
    "        numerator_zd = (X[:, np.newaxis, :] * p_z_wd).sum(axis=0)  # shape: (k, n)\n",
    "        denominator_zd = numerator_zd.sum(axis=0, keepdims=True)  # shape: (1, n)\n",
    "        new_p_z_d = (numerator_zd / (denominator_zd + 1e-10)).copy()  # 按列归一化\n",
    "\n",
    "        p_w_z, p_z_d = new_p_w_z.copy(), new_p_z_d.copy()\n",
    "    return p_w_z, p_z_d\n",
    "\n",
    "X = np.array([[0,0,1,1,0,0,0,0,0],\n",
    "              [0,0,0,0,0,1,0,0,1],\n",
    "              [0,1,0,0,0,0,0,1,0],\n",
    "              [0,0,0,0,0,0,1,0,1],\n",
    "              [1,0,0,0,0,1,0,0,0],\n",
    "              [1,1,1,1,1,1,1,1,1],\n",
    "              [1,0,1,0,0,0,0,0,0],\n",
    "              [0,0,0,0,0,0,1,0,1],\n",
    "              [0,0,0,0,0,2,0,0,1],\n",
    "              [1,0,1,0,0,0,0,1,0],\n",
    "              [0,0,0,1,1,0,0,0,0]])\n",
    "\n",
    "PLSA(X, k=4, max_iter=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
